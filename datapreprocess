import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from scipy import stats
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import r2_score
from sklearn.model_selection import train_test_split  
from sklearn.preprocessing import PolynomialFeatures  
from sklearn.linear_model import LinearRegression  
from sklearn.pipeline import make_pipeline  
from sklearn.metrics import mean_squared_error, r2_score 
from scipy import stats  
# Global drawing settings
plt.rcParams['figure.dpi'] = 300
plt.rcParams['font.family'] = 'serif'
plt.rcParams['font.serif'] = 'Times New Roman'
plt.rcParams['font.weight'] = 'normal'
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['axes.linewidth'] = 1
plt.rcParams['axes.titlesize'] = 14
plt.rcParams['axes.labelsize'] = 14
plt.rcParams['xtick.labelsize'] = 12
plt.rcParams['ytick.labelsize'] = 12
plt.rcParams['legend.fontsize'] = 12

#0. load data
pu='Proximate&Ultimate Analysis.xlsx'
hg='Trace Elements.xlsx'
ox='Oxides.xlsx'
des='my_description.xlsx'
pu0=pd.read_excel(pu,engine='openpyxl')
hg0=pd.read_excel(hg,engine='openpyxl')
ox0=pd.read_excel(ox,engine='openpyxl')
des0=pd.read_excel(des,engine='openpyxl')
pu=pd.DataFrame(pu0)
hg=pd.DataFrame(hg0)
ox=pd.DataFrame(ox0)
des=pd.DataFrame(des0)

hg=hg.iloc[:,[0,67,68]]
#忽略数据库中通过数学方法组合煤样基准样本和复合样本确定的整层样本，即使用A(平均值)和C(复合样本)
def filter_df(df, suffix=' Q'):  
    
    # 获取状态列的名字，这些列名以给定的后缀结尾  
    state_cols = [col for col in df.columns if col.endswith(suffix)]  
      
    # 创建一个函数来检查字符串中是否包含'a'或'c'，或者是否为空  
    def contains_a_or_c(row):  
        for col in state_cols:  
            value = row[col]  
            if pd.notna(value) and ('a' in str(value).lower() or 'c' in str(value).lower()):  
                return False 
        return True  
      
    # 应用这个函数到 DataFrame 的状态列，创建一个布尔序列  
    state_not_ac = df.apply(contains_a_or_c, axis=1)  
      
    # 使用这个布尔序列来筛选数据表，保留状态列中没有'a'或者'c'的行（包括空值）  
    filtered_df = df[state_not_ac]  
    #删除所有' Q'列
    def drop_state_columns(df, suffix=' Q'):  
        # 获取所有以给定后缀结尾的列名  
        state_cols = [col for col in df.columns if col.endswith(suffix)]  
      
        # 从DataFrame中删除这些列  
        df_without_state_cols = df.drop(columns=state_cols)  
      
        return df_without_state_cols
    filtered_df1=drop_state_columns(filtered_df)
    return filtered_df1  
hg_filtered=filter_df(hg)
ox_filtered=filter_df(ox)
pu_filtered=filter_df(pu)

#对pu表进行进一步处理
#删除较为不理想的数据'incomplete data'
# 获取'Proximate Validation'列的位置索引  
loc1 = pu_filtered.columns.get_loc(' Proximate Validation')  
loc2 = pu_filtered.columns.get_loc(' Ultimate Validation')
# 使用位置索引来删除含有'incomplete data'的行  
# 注意：使用位置索引通常不如直接使用列名清晰和高效  
pu1 = pu_filtered[pu_filtered.iloc[:, loc1] != 'Incomplete Data']
pu1 = pu1[pu1.iloc[:, loc1] != 'Suspect']
pu1 = pu1[pu1.iloc[:, loc2] != 'Incomplete Data']
pu1 = pu1[pu1.iloc[:, loc2] != 'Suspect']
pu1.drop(' Proximate Validation', axis=1, inplace=True)  
pu1.drop(' Ultimate Validation', axis=1, inplace=True)
#根据sample ID合并各表
df=pd.merge(hg_filtered,pu1,on='Sample ID',how='inner')
df=pd.merge(df,ox_filtered,on='Sample ID',how='inner')
df=pd.merge(df,des,on='Sample ID',how='inner')
df1 = df.drop(df.columns[0], axis=1)
# 计算每一列的NaN数量  
nan_counts = df1.isnull().sum()  
  
# 找出NaN数量大于1000的列名  
cols_to_drop = nan_counts[nan_counts > 1000].index  
  
# 从DataFrame中删除这些列  
df1_dropped = df1.drop(columns=cols_to_drop)  
  
# 现在df1_dropped是一个新的DataFrame，其中不包含NaN数量超过1000的列
df1_dropped.shape

df2=df1_dropped.dropna(axis=0)
df2.to_excel("2024511.xlsx")
#df2即为特征初选择结果


columns_to_extract = [' Hg',' Hg Q',' Sulfur',' Sulfur Q',' Pyritic Sulfur', ' Pyritic Sulfur Q',' Organic Sulfur',
                      ' Organic Sulfur Q',' Ash Deformation', ' Ash Deformation Q',
                       ' Standard Ash',' Standard Ash Q', ' Moisture',  ' Moisture Q',' Fixed Carbon',' Fixed Carbon Q',  
                       'SO3','SO3 Q', 'Fe2O3', 'Fe2O3 Q', 'SiO2', 'SiO2 Q', 'Al2O3','Al2O3 Q',
                      ' Fixed C Dry MMF',' Fixed C Dry MMF Q', 
                       ' Volatile Matter', ' Volatile Matter Q',
                       ' Btu',' Btu Q']

# 使用列名列表提取列
new_df = df[columns_to_extract]

import pandas as pd  
  
def filter_df(df, suffix=' Q'):  
    # 获取状态列的名字，这些列名以给定的后缀结尾  
    state_cols = [col for col in df.columns if col.endswith(suffix)]  
  
    # 创建一个函数来检查状态列是否为空  
    def is_state_column_empty(row):  
        for col in state_cols:  
            if not pd.isna(row[col]):  # 如果值不是空（NaN）  
                return False  
        return True  
  
    # 应用这个函数到 DataFrame 的状态列，创建一个布尔序列  
    state_is_empty = df.apply(is_state_column_empty, axis=1)  
  
    # 使用这个布尔序列来筛选数据表，保留状态列全为空的行  
    filtered_df = df[state_is_empty]  
  
    return filtered_df  
  
# 假设你有一个名为hg的DataFrame  
df_filtered = filter_df(new_df)  
# 现在你可以使用hg_filtered变量，它包含了状态列为空的行
#删除表格中所有' Q'列
df1=drop_state_columns(df_filtered)
#df1即为最终训练数据集
df1.to_excel("Test6_Final1.xlsx")

